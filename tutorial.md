# Tutorial

In this tutorial a data owner (data provider) will publish privatedata to the fitchain network and provide a description of the 
data science problem that needs to be solved. 
A data scientist (model provider) can apply to the project made available by data provider, inspect the data source(s) connected
to the project and provide a solution in the form of a machine learning model (using sklearn or tensorflow).

## Data provider
The following preliminary steps are required by data provider to submit a project

1. Run the IPFS daemon
`$ ipfs daemon`

2. Run Geth and synchronize to the Ethereum blockchain (for a test without involving real ETH, one can
connect to the Rinkeby testnet)

```bash
$ geth --rinkeby --ws --wsapi admin,eth,web3,personal,miner,rpc --wsaddr localhost --wsorigins="*"
```

3. Run the fitchain pod

```bash
$ cd fitchain-pod
$ node index
```

4. Run the fitchain pod dashboard (point the web browser to `localhost:9090`

```bash
cd fitchain-pod-ui
npm run dev
```

Use the dashboard to add data provider, add datasource with description, create project and submit

## Model provider

A data scientist needs to execute steps 1, 2, 3 in order to connect to the fitchain network with an Ethereum account.

He/she can use the fitchain command line interface to inspect the schema of the private data of data provider and 
to provide a solution to the data science problem of choice. 


### How to use the fitchain command line interface

To list all projects

```bash
$ fitchain projects
```

To show the info of the specific project

```bash
$ fitchain project project_id
```

Create a folder for the workspace

```bash
$ mkdir ~/my_folder
```

From the newly created folder, initialize the workspace with the relative project_id

```bash
$ cd ~/my_folder 
$ fitchain workspace init --name my_workspace project_id`
```

At this point a new Python model can be written and saved to disk (eg. to `my_model.py`) 
When done with the code, save it to the workspace

The machine learning model should be written between some boiler plate code that is generated by the command line 
interface. 
Such code (specific to the keras library for neural networks) looks like the one below:

```Python
from fitchain import Runtime

# initialize the runtime
runtime = Runtime()

# Load the dataset from the project
data = runtime.resolve("datasource_id")

# ###########################################
# WRITE KERAS/TENSORFLOW/SKLEARN MODEL HERE
#
#
#
#
#
# 
# ############################################

# For keras you need to perform the following steps:
from fitchain import keras as ker
model_id = 'my_model_id'
ker.store_train_params(model_id, x=train_data, y=train_labels)
ker.store_validate_params(model_id, x=valid_data, y=valid_labels)

# Fit model with entire data batch (can be prohibitive with many images)
ker.fit(model_id, model, x_train=train_data, y_train=train_labels, epochs=epochs)

```

After inspecting the synthetic data and writing the machine learning model, it is time to save it to the current workspace.
This can be done with

```bash
$ fitchain workspace save my_model.py
```

Model provider can ask data provider to start training the model with 

```bash
$ fitchain workspace run
```

Once the model has been deployed, model provider can view the jobs attached to the current workspace with

```bash
$ fitchain jobs my_workspace 
```
This will return the `job_id` of the submitted job


Model provider can inspect the logs of the current `job_id` with 

```bash
$ fitchain logs job_id
```

and the collected metrics (if available) with 

```bash
$ fitchain metrics job_id
```


Happy modeling!
